---
title: "twitter graphics"
author: "Cassidy Bargell"
date: "4/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rtweet)
library(httpuv)
library(gtrendsR)
library(lubridate)
library(maps)
library(pals)
library(viridis)
library(scico)
library(ggrepel)
library(infer)
library(tidyr)
library(stringr)
library(tidytext)
library(widyr)
data("stop_words")
```

```{r read in}

# read in RDS files to work with to avoid rate limits on twitter

football <- readRDS("sport-perceptions/raw-data/football.RDS")
rugby <- readRDS("sport-perceptions/raw-data/rugby.RDS")
nfl_tml <- readRDS("sport-perceptions/raw-data/nfl_tml.RDS")
wr_tml <- readRDS("sport-perceptions/raw-data/wr_tml.RDS")
sr_tml <- readRDS("sport-perceptions/raw-data/sr_tml.RDS")
```

```{r nfl_tml words}
nfl_tml %>%
  select(created_at, text, favorite_count, quote_count, retweet_count, reply_count) 

# Remove urls in tweets, and create list of words I want to search the tweets
# for. Capitalization are recognized separately.

words <- c("Concussion", "concussion", "CTE", "cte", "head", "Head", "Injury", "injury")
unique(words)

nfl_tml$stripped_text <- gsub("http.*","",  nfl_tml$text)
nfl_tml$stripped_text <- gsub("https.*","", nfl_tml$stripped_text)

nfl_tml_clean <- nfl_tml %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

# Get rid of pre-loaded group of words that have no context

nfl_tml_clean <- nfl_tml_clean %>%
  anti_join(stop_words, by = "word")
```

```{r football tweet words}
football %>%
  select(created_at, text, favorite_count, quote_count, retweet_count, reply_count) 

# Remove urls in tweets, and create list of words I want to search the tweets
# for. Capitalization are recognized separately.

football$stripped_text <- gsub("http.*","",  football$text)
football$stripped_text <- gsub("https.*","", football$stripped_text)

nfl_tml_clean <- nfl_tml %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

# Get rid of pre-loaded group of words that have no context

nfl_tml_clean <- nfl_tml_clean %>%
  anti_join(stop_words, by = "word")
```

```{r cleaning function}

# Create function for cleaning the tweet words based on what I did above

tweetclean <- function(tib) {

tib$stripped_text <- gsub("http.*","",  tib$text)
tib$stripped_text <- gsub("https.*","", tib$stripped_text)

tib_clean <- tib %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

tib_clean <- tib_clean %>%
  anti_join(stop_words, by = "word")
}

# Only want to use a sample of 4,000 of the tweets, as there are generally less
# rugby tweets than football in the US, so a random sample of most recent 4,000
# in the tibbles scrapped will then be used and bootstrap resampled.

football <- football %>%
  slice(1:4000)

rugby <- rugby %>%
  slice(1:4000)

football_clean <- tweetclean(football)
sr_clean <- tweetclean(sr_tml)
wr_clean <- tweetclean(wr_tml)
rugby_clean <- tweetclean(rugby)
```

```{r paired words}

# Search for paired words like head-injury

football_paired_words <- football %>%
  select(stripped_text) %>%
  unnest_tokens(paired_words, stripped_text, token = "ngrams", n = 2)

football_paired_words %>%
  count(paired_words, sort = TRUE)

football_separated_words <- football_paired_words %>%
  separate(paired_words, c("word1", "word2"), sep = " ")

football_filtered <- football_separated_words %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
football_words_counts <- football_filtered %>%
  count(word1, word2, sort = TRUE)

# cces %>% 
  # filter(gender == "Female") %>%
  # summarize(prop =  sum(trump == 1) / n())
```

```{r}

# Try to find proportions of cleaned tweets, can then bootstrap resample. 

football_prop <- football_clean %>%
  count(contains_word = (word == "concussion" | word == "concussions" | word == "cte" | word == "head" | word == "injury" |  word == "injuries")) %>%
  mutate(total = sum(n)) %>%
  filter(contains_word == 'TRUE') %>%
  mutate(prop = (n / total) * 100)

# Make function to make that process easier

proportion_words <- function(tib){
  tib %>%
  count(contains_word = (word == "concussion" | word == "concussions" | word == "cte" | word == "head" | word == "injury" |  word == "injuries")) %>%
  mutate(total = sum(n)) %>%
  filter(contains_word == 'TRUE') %>%
  mutate(prop = (n / total) * 100)
}

rugby_prop <- proportion_words(rugby_clean)
sr_prop <- proportion_words(sr_clean)
wr_prop <- proportion_words(wr_clean)
nfl_prop <- proportion_words(nfl_tml_clean)
```

```{r bootstrap resample}

# Bootstrap resample the football data

football_bootstrap <- football %>%
  rep_sample_n(size = 4000, replace = TRUE, reps = 100) %>%
  tweetclean() %>%
  group_by(replicate) %>%
  proportion_words() %>%
  select(replicate, n, total, prop)

# Create function to boostrap the words more easily

bootstrap_prop <- function(tib){
  tib %>%
  rep_sample_n(size = 4000, replace = TRUE, reps = 3) %>%
  tweetclean() %>%
  group_by(replicate) %>%
  proportion_words() %>%
  select(replicate, n, total, prop)
}

bootstrap_prop(rugby)
```


