---
title: "collecting and cleaning"
author: "Cassidy Bargell"
date: "4/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rtweet)
library(httpuv)
library(gtrendsR)
library(lubridate)
library(maps)
library(pals)
library(viridis)
library(scico)
library(ggrepel)
library(tidytext)
data("stop_words")
```

```{r twitter setup}

# Twitter set-up stuff

app_name <- "clb_twitter_app"
api_key <- "qFVEvxpEi0OmgWSmuIgG7RMPx"
api_secret_key <- "4KAvZL1OFZIITkrxY7xou9dAsTurvlvrXcd5edKX7NoVJ1sGyf"
token <- create_token(
  app = "clb_twitter_app",
  consumer_key = api_key,
  consumer_secret = api_secret_key)

path_to_token <- file.path(path.expand("~"), ".twitter_token.rds")
saveRDS(token, path_to_token)
env_var <- paste0("TWITTER_PAT=", path_to_token)
cat(env_var, file = file.path(path.expand("~"), ".Renviron"), 
  fill = TRUE, append = TRUE)

readRenviron("~/.Renviron")

usa <- lookup_coords(address = "usa", apikey = "88a679312c139a94aa3d3210ef78e8a8e1a925f6")
```

```{r google}

# Find initial google search trends on rugby 

google_rugby <- gtrends(c("rugby"), geo = c("US"),
                        gprop = "web", time = "all")


# Interest by region tibble to plot

rugby_interest_by_region <- as_tibble(google_rugby$interest_by_region)
rugby_interest_by_region <- rugby_interest_by_region %>% 
  mutate(region = str_to_lower(location))

saveRDS(rugby_interest_by_region, file = "rugby-tweet/rugby_interest_by_region.RDS")

# Create map of US states


google_rugby <- gtrends(c("rugby"), geo = c("US"),
                        gprop = "web", time = "all")

saveRDS(google_rugby, file = "rugby-tweet/google_rugby.RDS")

states_map <- ggplot2::map_data("state")

saveRDS(states_map, file = "rugby-tweet/states_map.RDS")

saveRDS(google_rugby)

# Join data

rugby_merged <- merge(states_map, rugby_interest_by_region, by = "region")
rugby_merged <- rugby_interest_by_region %>% dplyr::left_join(x = ., 
                                                            y = states_map, 
                                                            by = "region")

saveRDS(rugby_merged, file = "rugby-tweet/rugby_merged.RDS")

# Create map theme so clean-up is easier

("milestone-6/map_theme.R")

map_theme = function() {
    theme(axis.title = element_blank()) +
    theme(axis.text = element_blank()) +
    theme(axis.ticks = element_blank()) + 
    theme(legend.title = element_blank()) +
  theme(panel.grid.major = element_blank())
}

# Plot map 

plot_rgsearch <- ggplot(rugby_merged, aes(x = long, y = lat)) +
  geom_polygon(aes(group = group, 
                   fill = log(hits)), 
               colour = "white") +
  scale_fill_viridis_c(option = "plasma",
                       direction = -1) +
  theme_minimal() + 
  labs(title = "Google Search Hits for 'Rugby' Since 2004", 
       subtitle = "Search Hits Normalized to Compare Relative Popularity",
       caption = "Google Trends: Search results are normalized to the time and
       location of a query. Each data point is divided by the total searches of
       the geography and time range it represents to compare relative popularity.") +
  map_theme()
```

```{r tweets, cache = TRUE}
football <- search_tweets("football", n = 10000, include_rts = FALSE, geocode = usa) %>% 
  select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)

file.create("football.RDS")
saveRDS(football, file = "football.RDS")

rugby <- search_tweets("rugby", n = 10000, include_rts = FALSE, geocode = usa) %>% 
  select(user_id, 
         created_at, 
         screen_name, 
         text, 
         is_quote, 
         is_retweet, 
         retweet_count, 
         favorite_count, 
         quote_count, 
         reply_count, 
         hashtags)

file.create("rugby.RDS")
saveRDS(rugby, file = "rugby.RDS")

nfl_tml <- get_timeline("NFL", n = 3200)
wr_tml <- get_timeline("WorldRugby", n = 3200)
sr <- get_timeline("SuperRugbyNZ", n = 3200)

file.create("nfl_tml.RDS")
saveRDS(nfl_tml, file = "raw-data/nfl_tml.RDS")

file.create("wr_tml.RDS")
saveRDS(wr_tml, file = "raw-data/wr_tml.RDS")

file.create("sr_tml.RDS")
saveRDS(sr, file = "raw-data/sr_tml.RDS")

 # other account/sport ideas = USWNT (soccer), ussoccer, usarugby
```

```{r read in}

# read in RDS files to work with to avoid rate limits on twitter

football <- readRDS("raw-data/football.RDS")
rugby <- readRDS("raw-data/rugby.RDS")
nfl_tml <- readRDS("raw-data/nfl_tml.RDS")
wr_tml <- readRDS("raw-data/wr_tml.RDS")
sr_tml <- readRDS("raw-data/sr_tml.RDS")
```

```{r nfl_tml words}
nfl_tml %>%
  select(created_at, text, favorite_count, quote_count, retweet_count, reply_count) 

# Remove urls in tweets, and create list of words I want to search the tweets
# for. Capitalization are recognized separately.

words <- c("Concussion", "concussion", "CTE", "cte", "head", "Head", "Injury", "injury")
unique(words)

nfl_tml$stripped_text <- gsub("http.*","",  nfl_tml$text)
nfl_tml$stripped_text <- gsub("https.*","", nfl_tml$stripped_text)

nfl_tml_clean <- nfl_tml %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

# Get rid of pre-loaded group of words that have no context

nfl_tml_clean <- nfl_tml_clean %>%
  anti_join(stop_words, by = "word")
```

```{r football tweet words}
football %>%
  select(created_at, text, favorite_count, quote_count, retweet_count, reply_count) 

# Remove urls in tweets, and create list of words I want to search the tweets
# for. Capitalization are recognized separately.

football$stripped_text <- gsub("http.*","",  football$text)
football$stripped_text <- gsub("https.*","", football$stripped_text)

nfl_tml_clean <- nfl_tml %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

# Get rid of pre-loaded group of words that have no context

nfl_tml_clean <- nfl_tml_clean %>%
  anti_join(stop_words, by = "word")
```

```{r cleaning function}

# Create function for cleaning the tweet words based on what I did above

tweetclean <- function(tib) {

tib$stripped_text <- gsub("http.*","",  tib$text)
tib$stripped_text <- gsub("https.*","", tib$stripped_text)

tib_clean <- tib %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) 

tib_clean <- tib_clean %>%
  anti_join(stop_words, by = "word")
}

football_clean <- tweetclean(football)
sr_clean <- tweetclean(sr_tml)
wr_clean <- tweetclean(wr_tml)
rugby_clean <- tweetclean(rugby)
```
